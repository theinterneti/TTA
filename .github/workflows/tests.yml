name: CI/CD Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      - name: Sync dependencies
        run: uv sync --all-extras --dev

      - name: Cache pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}

      - name: Run pre-commit hooks
        run: uv run pre-commit run --all-files --show-diff-on-failure

      - name: Check code formatting (black)
        run: uv run black --check --diff src/ tests/

      - name: Check import sorting (isort)
        run: uv run isort --check-only --diff src/ tests/

      - name: Lint code (ruff)
        run: uv run ruff check src/ tests/ --output-format=github

      - name: Type checking (mypy)
        run: uv run mypy src/ --show-error-codes
        continue-on-error: true  # Allow mypy failures for now

      - name: Security scan (bandit)
        run: uv run bandit -r src/ -f json -o bandit-report.json || true

      - name: Upload bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-security-report
          path: bandit-report.json

  unit:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      - name: Sync dependencies
        run: uv sync --all-extras --dev

      - name: Run unit tests with coverage
        run: uv run pytest tests/ --cov=src --cov-report=xml --cov-report=html --cov-report=term-missing -v

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        if: always()
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Upload coverage HTML report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-html-report
          path: htmlcov/

  performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [unit, integration]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      - name: Sync dependencies
        run: uv sync --all-extras --dev

      - name: Run performance benchmarks
        run: |
          uv run pytest tests/performance/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            -v
        continue-on-error: true

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: benchmark-results.json

  documentation-check:
    name: Documentation Quality Check
    runs-on: ubuntu-latest
    needs: code-quality

    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      - name: Sync dependencies
        run: uv sync --all-extras --dev

      - name: Install documentation dependencies
        run: uv pip install sphinx sphinx-rtd-theme sphinx-copybutton sphinx-tabs myst-parser

      - name: Check documentation builds
        run: |
          cd docs/sphinx
          uv run sphinx-build -b html . _build/html -W --keep-going
        env:
          PYTHONPATH: ${{ github.workspace }}/src

      - name: Check documentation coverage
        run: |
          uv run interrogate src/ --generate-badge . --badge-format svg
          uv run interrogate src/ --verbose > doc-coverage-report.txt

      - name: Upload documentation artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: documentation-check
          path: |
            docs/sphinx/_build/html/
            interrogate_badge.svg
            doc-coverage-report.txt

  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit
    services:
      neo4j:
        image: neo4j:5-community
        env:
          NEO4J_AUTH: neo4j/testpassword
          NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
        ports:
          - 7687:7687
        options: >-
          --health-cmd="/var/lib/neo4j/bin/cypher-shell -u neo4j -p testpassword 'RETURN 1'"
          --health-interval=10s --health-timeout=5s --health-retries=10
      redis:
        image: redis:7
        ports:
          - 6379:6379
        options: >-
          --health-cmd="redis-cli ping || exit 1"
          --health-interval=5s --health-timeout=3s --health-retries=10
    env:
      RUN_NEO4J_TESTS: "1"
      RUN_REDIS_TESTS: "1"
      TEST_NEO4J_URI: "bolt://localhost:7687"
      TEST_NEO4J_USERNAME: "neo4j"
      TEST_NEO4J_PASSWORD: "testpassword"
      TEST_REDIS_URI: "redis://localhost:6379/0"
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      - name: Sync dependencies
        run: uv sync --all-extras --dev

      - name: Wait for services to be ready
        run: |
          echo "Waiting for Neo4j..."
          timeout 60 bash -c 'until uv run python -c "from neo4j import GraphDatabase; GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"testpassword\")).verify_connectivity()"; do sleep 2; done'
          echo "Waiting for Redis..."
          timeout 30 bash -c 'until redis-cli -h localhost ping; do sleep 1; done'

      - name: Run integration tests (Neo4j, Redis)
        run: uv run pytest tests/ --neo4j --redis --cov=src --cov-report=xml --cov-report=term-missing -v

      - name: Upload integration coverage
        uses: codecov/codecov-action@v4
        if: always()
        with:
          file: ./coverage.xml
          flags: integration
          name: codecov-integration
          fail_ci_if_error: false

  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    needs: [code-quality, unit, integration]
    if: always()
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v1
      - name: Sync dependencies
        run: uv sync --all-extras --dev

      - name: Download coverage reports
        uses: actions/download-artifact@v4
        with:
          name: coverage-report
          path: htmlcov/
        continue-on-error: true

      - name: Check coverage threshold
        run: |
          # Extract coverage percentage from previous run
          COVERAGE=$(uv run pytest tests/ --cov=src --cov-report=term-missing | grep "TOTAL" | awk '{print $4}' | sed 's/%//')
          echo "Current coverage: ${COVERAGE}%"

          # Set minimum coverage threshold (start low, increase gradually)
          MIN_COVERAGE=70

          if (( $(echo "$COVERAGE < $MIN_COVERAGE" | bc -l) )); then
            echo "âŒ Coverage ${COVERAGE}% is below minimum threshold ${MIN_COVERAGE}%"
            exit 1
          else
            echo "âœ… Coverage ${COVERAGE}% meets minimum threshold ${MIN_COVERAGE}%"
          fi
        continue-on-error: true

      - name: Quality gate summary
        run: |
          echo "## Quality Gate Results" >> $GITHUB_STEP_SUMMARY
          echo "| Check | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY

          # Check job statuses
          if [ "${{ needs.code-quality.result }}" == "success" ]; then
            echo "| Code Quality | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Code Quality | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.unit.result }}" == "success" ]; then
            echo "| Unit Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Unit Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.integration.result }}" == "success" ]; then
            echo "| Integration Tests | âœ… Passed |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Integration Tests | âŒ Failed |" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“Š [Coverage Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”’ [Security Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
