# Narrative Arc Orchestrator - Test Coverage Improvement Plan

**Date**: 2025-10-13
**Component**: Narrative Arc Orchestrator
**Current Coverage**: 42.9% (verified via GitHub Issue #42)
**Target Coverage**: 70%+
**Coverage Gap**: 27.1%
**Priority**: P2

---

## Executive Summary

The Narrative Arc Orchestrator component requires **27.1% additional test coverage** to meet the 70% staging promotion threshold. This plan outlines a systematic approach to achieve 70%+ coverage through targeted test development.

**Current Status**:
- ✅ Code Quality: All checks passing (linting, type checking, security)
- ✅ Existing Tests: All passing (100% pass rate)
- ❌ Coverage: 42.9% (below 70% threshold)

**Estimated Effort**: 40-80 hours (1-2 weeks)
**Target Completion**: 2025-10-27
**Staging Deployment**: After 70%+ coverage achieved

---

## Current Coverage Analysis

### Coverage by File (from local test run)

| File | Current Coverage | Missing Lines | Priority |
|------|------------------|---------------|----------|
| **scale_manager.py** | 53.39% | 70 lines | **HIGH** |
| **impact_analysis.py** | 53.44% | 31 lines | **HIGH** |
| **causal_graph.py** | 42.86% | 7 lines | **MEDIUM** |
| **models.py** | 76.47% | 12 lines | **LOW** |
| **resolution_engine.py** | 75.00% | 2 lines | **LOW** |
| **conflict_detection.py** | 100.00% | 0 lines | ✅ **COMPLETE** |

**Total**: 380 statements, 122 missing (67.9% covered when running single test file)

**Note**: GitHub Issue #42 reports 42.9% coverage (running full test suite), which is the authoritative figure.

---

## Test Coverage Improvement Strategy

### Phase 1: scale_manager.py (Priority: HIGH)

**Current Coverage**: 53.39%
**Target Coverage**: 75%+
**Estimated Gain**: +10-12%
**Effort**: 20-30 hours

#### Missing Coverage Areas

1. **Event Creation Logic** (lines 119-133)
   - Test event creation with various scale types
   - Test event validation
   - Test event metadata generation

2. **Scale Window Calculations** (lines 184-202)
   - Test window boundary calculations
   - Test overlapping windows
   - Test edge cases (empty windows, single-event windows)

3. **Conflict Resolution** (lines 207-224)
   - Test conflict detection between scales
   - Test conflict resolution strategies
   - Test conflict priority handling

4. **Async Initialization** (lines 245-252)
   - Test async setup
   - Test initialization error handling
   - Test cleanup on failure

#### Test Scenarios to Add

```python
# tests/test_narrative_arc_orchestrator_scale_manager.py

class TestScaleManagerEventCreation:
    """Test event creation logic (lines 119-133)"""

    def test_create_event_with_valid_scale_type(self):
        """Test creating events with different scale types"""
        pass

    def test_create_event_validates_input(self):
        """Test event creation validates required fields"""
        pass

    def test_create_event_generates_metadata(self):
        """Test event metadata is correctly generated"""
        pass

    def test_create_event_handles_invalid_scale_type(self):
        """Test error handling for invalid scale types"""
        pass


class TestScaleManagerWindowCalculations:
    """Test scale window calculations (lines 184-202)"""

    def test_calculate_window_boundaries(self):
        """Test window boundary calculations"""
        pass

    def test_handle_overlapping_windows(self):
        """Test handling of overlapping time windows"""
        pass

    def test_handle_empty_windows(self):
        """Test edge case: empty windows"""
        pass

    def test_handle_single_event_windows(self):
        """Test edge case: windows with single event"""
        pass


class TestScaleManagerConflictResolution:
    """Test conflict resolution (lines 207-224)"""

    def test_detect_scale_conflicts(self):
        """Test conflict detection between scales"""
        pass

    def test_resolve_conflicts_by_priority(self):
        """Test conflict resolution using priority"""
        pass

    def test_resolve_conflicts_by_timestamp(self):
        """Test conflict resolution using timestamps"""
        pass


class TestScaleManagerAsyncInitialization:
    """Test async initialization (lines 245-252)"""

    async def test_async_setup_success(self):
        """Test successful async initialization"""
        pass

    async def test_async_setup_error_handling(self):
        """Test error handling during initialization"""
        pass

    async def test_cleanup_on_initialization_failure(self):
        """Test cleanup when initialization fails"""
        pass
```

**Estimated Tests**: 15-20 new tests
**Estimated Coverage Gain**: +10-12%

---

### Phase 2: impact_analysis.py (Priority: HIGH)

**Current Coverage**: 53.44%
**Target Coverage**: 70%+
**Estimated Gain**: +8-10%
**Effort**: 15-25 hours

#### Missing Coverage Areas

1. **Null Checks and Edge Cases** (various lines)
   - Test handling of None/null inputs
   - Test empty collections
   - Test boundary values

2. **Error Handling Paths** (various lines)
   - Test exception handling
   - Test recovery from errors
   - Test error propagation

#### Test Scenarios to Add

```python
# tests/test_narrative_arc_orchestrator_impact_analysis.py

class TestImpactAnalysisNullHandling:
    """Test null/None input handling"""

    def test_analyze_with_none_input(self):
        """Test handling of None input"""
        pass

    def test_analyze_with_empty_events(self):
        """Test handling of empty event list"""
        pass

    def test_analyze_with_missing_required_fields(self):
        """Test handling of events with missing fields"""
        pass


class TestImpactAnalysisErrorHandling:
    """Test error handling and recovery"""

    def test_handle_invalid_event_type(self):
        """Test error handling for invalid event types"""
        pass

    def test_handle_malformed_event_data(self):
        """Test error handling for malformed data"""
        pass

    def test_recover_from_analysis_failure(self):
        """Test recovery when analysis fails"""
        pass

    def test_propagate_critical_errors(self):
        """Test that critical errors are propagated"""
        pass


class TestImpactAnalysisBoundaryConditions:
    """Test boundary conditions and edge cases"""

    def test_analyze_single_event(self):
        """Test analysis with single event"""
        pass

    def test_analyze_maximum_events(self):
        """Test analysis with large number of events"""
        pass

    def test_analyze_with_zero_impact(self):
        """Test events with zero impact"""
        pass
```

**Estimated Tests**: 10-15 new tests
**Estimated Coverage Gain**: +8-10%

---

### Phase 3: causal_graph.py (Priority: MEDIUM)

**Current Coverage**: 42.86%
**Target Coverage**: 70%+
**Estimated Gain**: +5-7%
**Effort**: 10-15 hours

#### Missing Coverage Areas

1. **Graph Validation** (lines 25-29)
   - Test graph structure validation
   - Test node validation
   - Test edge validation

2. **Cycle Detection** (line 16)
   - Test cycle detection algorithm
   - Test handling of cyclic graphs
   - Test acyclic graph validation

#### Test Scenarios to Add

```python
# tests/test_narrative_arc_orchestrator_causal_graph.py

class TestCausalGraphValidation:
    """Test graph validation (lines 25-29)"""

    def test_validate_graph_structure(self):
        """Test validation of graph structure"""
        pass

    def test_validate_nodes(self):
        """Test node validation"""
        pass

    def test_validate_edges(self):
        """Test edge validation"""
        pass

    def test_reject_invalid_graph(self):
        """Test rejection of invalid graphs"""
        pass


class TestCausalGraphCycleDetection:
    """Test cycle detection (line 16)"""

    def test_detect_simple_cycle(self):
        """Test detection of simple cycles"""
        pass

    def test_detect_complex_cycle(self):
        """Test detection of complex cycles"""
        pass

    def test_accept_acyclic_graph(self):
        """Test acceptance of acyclic graphs"""
        pass

    def test_handle_self_loops(self):
        """Test handling of self-loops"""
        pass
```

**Estimated Tests**: 8-10 new tests
**Estimated Coverage Gain**: +5-7%

---

## Implementation Timeline

### Week 1 (2025-10-14 to 2025-10-20)

**Monday-Tuesday (2025-10-14 to 2025-10-15)**:
- Set up test file structure
- Implement scale_manager.py event creation tests (5-7 tests)
- **Target**: +3-4% coverage

**Wednesday-Thursday (2025-10-16 to 2025-10-17)**:
- Implement scale_manager.py window calculation tests (4-5 tests)
- Implement scale_manager.py conflict resolution tests (3-4 tests)
- **Target**: +4-5% coverage

**Friday (2025-10-18)**:
- Implement scale_manager.py async initialization tests (3-4 tests)
- Run coverage verification
- **Target**: +3-4% coverage
- **Week 1 Total**: +10-13% coverage (52.9% → 62.9-65.9%)

### Week 2 (2025-10-21 to 2025-10-27)

**Monday-Tuesday (2025-10-21 to 2025-10-22)**:
- Implement impact_analysis.py null handling tests (3-4 tests)
- Implement impact_analysis.py error handling tests (4-5 tests)
- **Target**: +5-6% coverage

**Wednesday-Thursday (2025-10-23 to 2025-10-24)**:
- Implement impact_analysis.py boundary condition tests (3-4 tests)
- Implement causal_graph.py validation tests (4-5 tests)
- **Target**: +4-5% coverage

**Friday (2025-10-25)**:
- Implement causal_graph.py cycle detection tests (4-5 tests)
- Run final coverage verification
- **Target**: +3-4% coverage
- **Week 2 Total**: +12-15% coverage (62.9-65.9% → 74.9-80.9%)

**Target Achievement**: 70%+ coverage by 2025-10-27 ✅

---

## Verification & Validation

### Coverage Measurement

**Command**:
```bash
uv run pytest tests/ \
  --cov=src/components/narrative_arc_orchestrator \
  --cov-report=term-missing \
  --cov-report=html:htmlcov/narrative_arc_orchestrator \
  --cov-report=json:narrative_arc_coverage.json \
  -v
```

**Success Criteria**:
- ✅ Total coverage ≥70%
- ✅ All new tests passing
- ✅ No regression in existing tests
- ✅ All quality checks still passing (linting, type checking, security)

### Daily Progress Tracking

Create a progress tracking file to monitor daily coverage gains:

```bash
# scripts/track-narrative-arc-coverage.sh
#!/bin/bash

DATE=$(date +%Y-%m-%d)
COVERAGE=$(uv run pytest tests/ \
  --cov=src/components/narrative_arc_orchestrator \
  --cov-report=json:coverage.json \
  -q | grep -oP '\d+%' | head -1)

echo "$DATE: $COVERAGE" >> docs/component-promotion/narrative_arc_coverage_progress.log
echo "Current coverage: $COVERAGE"
```

---

## Risk Mitigation

### Risk 1: Coverage Gain Lower Than Expected
**Mitigation**: Focus on high-impact areas first (scale_manager.py), adjust plan if needed

### Risk 2: Tests Reveal Bugs in Uncovered Code
**Mitigation**: Fix bugs as discovered, may extend timeline but improves quality

### Risk 3: Timeline Slippage
**Mitigation**: Prioritize high-impact tests, can achieve 70% with Phase 1+2 only if needed

---

## Success Metrics

### Immediate (Week 1)
- ✅ 15-20 new tests implemented
- ✅ Coverage increased to 62.9-65.9%
- ✅ All tests passing

### Final (Week 2)
- ✅ 33-45 total new tests implemented
- ✅ Coverage ≥70% (target: 74.9-80.9%)
- ✅ All tests passing
- ✅ Ready for staging promotion

---

## Related Documentation

- **Component Status**: `docs/component-promotion/COMPONENT_MATURITY_STATUS.md`
- **Priority List**: `docs/component-promotion/TOP_3_PRIORITIES.md`
- **GitHub Issue #42**: Component Status Report
- **Promotion Issue**: #45

---

**Created**: 2025-10-13
**Target Start**: 2025-10-21 (after Carbon, Model Management, Gameplay Loop promotions)
**Target Completion**: 2025-10-27
**Staging Deployment**: 2025-10-28 (after 70%+ coverage achieved)
