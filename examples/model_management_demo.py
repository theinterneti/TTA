#!/usr/bin/env python3
"""
Model Management System Demo

This script demonstrates the comprehensive model management system for TTA,
showcasing various providers, model selection, and generation capabilities.
"""

import asyncio
import logging
import os
import sys
from pathlib import Path

# Add the src directory to the Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from components.model_management import (
    ModelManagementComponent,
    ModelRequirements,
    TaskType,
)

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def demo_basic_generation():
    """Demonstrate basic text generation with automatic model selection."""
    print("\n" + "=" * 60)
    print("DEMO: Basic Text Generation")
    print("=" * 60)

    # Configuration for the demo
    config = {
        "model_management": {
            "enabled": True,
            "default_provider": "openrouter",
            "providers": {
                "openrouter": {
                    "enabled": True,
                    "api_key": os.getenv("OPENROUTER_API_KEY", "demo-key"),
                    "free_models_only": True,
                    "base_url": "https://openrouter.ai/api/v1",
                }
            },
            "selection_strategy": {
                "algorithm": "performance_based",
                "prefer_free_models": True,
                "therapeutic_safety_threshold": 7.0,
            },
        }
    }

    # Initialize the model management component
    component = ModelManagementComponent(config)

    try:
        # Start the component
        print("Starting model management system...")
        await component.start()

        # Generate text with automatic model selection
        print("\nGenerating therapeutic narrative...")
        response = await component.generate_text(
            prompt="Tell me a short story about someone overcoming their fear of public speaking",
            task_type=TaskType.THERAPEUTIC_NARRATIVE,
            max_tokens=500,
            temperature=0.7,
        )

        if response:
            print(f"\nGenerated by: {response.model_id}")
            print(f"Provider: {response.metadata.get('provider', 'unknown')}")
            print(f"Latency: {response.latency_ms:.0f}ms")
            print(
                f"Tokens: {response.usage.get('total_tokens', 'unknown') if response.usage else 'unknown'}"
            )
            print(f"\nResponse:\n{response.text}")
        else:
            print("‚ùå No response generated")

    except Exception as e:
        print(f"‚ùå Error: {e}")
    finally:
        # Stop the component
        await component.stop()


async def demo_model_selection():
    """Demonstrate intelligent model selection based on requirements."""
    print("\n" + "=" * 60)
    print("DEMO: Intelligent Model Selection")
    print("=" * 60)

    config = {
        "model_management": {
            "enabled": True,
            "providers": {
                "openrouter": {
                    "enabled": True,
                    "api_key": os.getenv("OPENROUTER_API_KEY", "demo-key"),
                    "free_models_only": True,
                },
                "ollama": {
                    "enabled": True,
                    "base_url": "http://localhost:11434",
                    "docker_enabled": False,  # Assume Ollama is running locally
                },
            },
        }
    }

    component = ModelManagementComponent(config)

    try:
        await component.start()

        # Test different task types and requirements
        test_cases = [
            {
                "name": "Quick Chat Response",
                "requirements": ModelRequirements(
                    task_type=TaskType.GENERAL_CHAT,
                    max_latency_ms=2000,
                    min_quality_score=6.0,
                ),
                "prompt": "Hello, how are you today?",
            },
            {
                "name": "Therapeutic Narrative",
                "requirements": ModelRequirements(
                    task_type=TaskType.THERAPEUTIC_NARRATIVE,
                    therapeutic_safety_required=True,
                    min_quality_score=7.0,
                    context_length_needed=2048,
                ),
                "prompt": "Create a story about building self-confidence",
            },
            {
                "name": "Creative Writing",
                "requirements": ModelRequirements(
                    task_type=TaskType.CREATIVE_WRITING,
                    max_cost_per_token=0.001,
                    min_quality_score=7.5,
                ),
                "prompt": "Write a poem about the beauty of nature",
            },
        ]

        for test_case in test_cases:
            print(f"\n--- {test_case['name']} ---")

            # Select model based on requirements
            model_instance = await component.select_model(test_case["requirements"])

            if model_instance:
                print(f"Selected model: {model_instance.model_id}")

                # Generate response
                response = await component.generate_text(
                    test_case["prompt"],
                    task_type=test_case["requirements"].task_type,
                    max_tokens=200,
                )

                if response:
                    print(f"Response preview: {response.text[:100]}...")
                else:
                    print("‚ùå Generation failed")
            else:
                print("‚ùå No suitable model found")

    except Exception as e:
        print(f"‚ùå Error: {e}")
    finally:
        await component.stop()


async def demo_system_monitoring():
    """Demonstrate system monitoring and performance tracking."""
    print("\n" + "=" * 60)
    print("DEMO: System Monitoring & Performance")
    print("=" * 60)

    config = {
        "model_management": {
            "enabled": True,
            "providers": {
                "openrouter": {
                    "enabled": True,
                    "api_key": os.getenv("OPENROUTER_API_KEY", "demo-key"),
                    "free_models_only": True,
                }
            },
            "performance_monitoring": {"enabled": True, "real_time_monitoring": True},
        }
    }

    component = ModelManagementComponent(config)

    try:
        await component.start()

        # Get system status
        print("System Status:")
        status = await component.get_system_status()
        print(f"  Initialized: {status['initialized']}")
        print(f"  Active models: {status['active_models']}")
        print(f"  Available providers: {len(status['providers'])}")

        if status["system_resources"]:
            resources = status["system_resources"]
            print(f"  System RAM: {resources.get('total_ram_gb', 'unknown')} GB")
            print(f"  GPU count: {resources.get('gpu_count', 'unknown')}")

        # Get available models
        print("\nAvailable Models:")
        models = await component.get_available_models()
        for i, model in enumerate(models[:5]):  # Show first 5 models
            print(f"  {i + 1}. {model.model_id}")
            print(f"     Provider: {model.provider_type.value}")
            print(f"     Free: {model.is_free}")
            print(f"     Context: {model.context_length} tokens")
            if model.therapeutic_safety_score:
                print(f"     Safety Score: {model.therapeutic_safety_score}/10")

        if len(models) > 5:
            print(f"  ... and {len(models) - 5} more models")

        # Test model connectivity
        if models:
            print(f"\nTesting connectivity to: {models[0].model_id}")
            test_result = await component.test_model_connectivity(
                models[0].model_id, models[0].provider_type.value
            )

            print(f"  Status: {test_result['status']}")
            print(f"  Healthy: {test_result['healthy']}")
            if test_result.get("latency_ms"):
                print(f"  Latency: {test_result['latency_ms']:.0f}ms")
            if test_result.get("error"):
                print(f"  Error: {test_result['error']}")

    except Exception as e:
        print(f"‚ùå Error: {e}")
    finally:
        await component.stop()


async def demo_hardware_detection():
    """Demonstrate hardware detection and model recommendations."""
    print("\n" + "=" * 60)
    print("DEMO: Hardware Detection & Recommendations")
    print("=" * 60)

    config = {
        "model_management": {
            "enabled": True,
            "hardware_detection": {"enabled": True, "gpu_detection": True},
        }
    }

    component = ModelManagementComponent(config)

    try:
        await component.start()

        # Get hardware information
        print("Detected Hardware:")
        if component.system_resources:
            resources = component.system_resources
            print(f"  CPU Cores: {resources.get('cpu_cores', 'unknown')}")
            print(f"  Total RAM: {resources.get('total_ram_gb', 'unknown')} GB")
            print(f"  Available RAM: {resources.get('available_ram_gb', 'unknown')} GB")
            print(f"  GPU Count: {resources.get('gpu_count', 0)}")

            if resources.get("gpus"):
                for i, gpu in enumerate(resources["gpus"]):
                    print(
                        f"    GPU {i}: {gpu.get('name', 'Unknown')} "
                        f"({gpu.get('memory_gb', 'unknown')} GB)"
                    )

        # Get model recommendations for different tasks
        task_types = [
            TaskType.GENERAL_CHAT,
            TaskType.THERAPEUTIC_NARRATIVE,
            TaskType.CREATIVE_WRITING,
        ]

        print("\nModel Recommendations by Task:")
        for task_type in task_types:
            print(f"\n  {task_type.value}:")
            recommendations = await component.get_model_recommendations(task_type)

            for i, model_id in enumerate(recommendations[:3]):  # Show top 3
                print(f"    {i + 1}. {model_id}")

    except Exception as e:
        print(f"‚ùå Error: {e}")
    finally:
        await component.stop()


async def main():
    """Run all demonstrations."""
    print("TTA Model Management System Demo")
    print("=" * 60)

    # Check for required environment variables
    if not os.getenv("OPENROUTER_API_KEY"):
        print("‚ö†Ô∏è  Warning: OPENROUTER_API_KEY not set. Some demos may fail.")
        print("   Set it with: export OPENROUTER_API_KEY='your-key-here'")

    try:
        # Run demonstrations
        await demo_hardware_detection()
        await demo_system_monitoring()
        await demo_model_selection()

        # Only run generation demo if API key is available
        if os.getenv("OPENROUTER_API_KEY"):
            await demo_basic_generation()
        else:
            print("\n‚ö†Ô∏è  Skipping generation demo - no API key provided")

        print("\n" + "=" * 60)
        print("Demo completed successfully! üéâ")
        print("=" * 60)

    except KeyboardInterrupt:
        print("\n\nDemo interrupted by user.")
    except Exception as e:
        print(f"\n‚ùå Demo failed with error: {e}")
        logger.exception("Demo error details:")


if __name__ == "__main__":
    # Run the demo
    asyncio.run(main())
